{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7ac099e-2eb4-4915-889c-69b0ff4c786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Initialize lists to store the titles, paths, and document contents\n",
    "titles = []\n",
    "paths = []\n",
    "docs = []\n",
    "\n",
    "# Define the directory you want to traverse\n",
    "#directory = 'AIG200-CAPSTONE/Dataset'\n",
    "directory = r'C:\\Users\\daniel mensah\\Desktop\\AI_Projects\\DL\\AIG200-Capstone\\Dataset'\n",
    "\n",
    "# Traverse the directory\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.txt'):  # For each text file\n",
    "            titles.append(os.path.splitext(filename)[0])\n",
    "            txt_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "            txt_path = os.path.join(root, txt_filename)\n",
    "            \n",
    "            paths.append(txt_path)\n",
    "            #print(txt_path)\n",
    "            with open(txt_path, encoding=\"utf8\") as fo:\n",
    "                docs.append(unidecode(fo.read()))  # Append the text to docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da2f4da4-4097-4826-b064-ae97b83cb0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Keywords: 100%|██████████| 189/189 [07:00<00:00,  2.23s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from keybert import KeyBERT\n",
    "\n",
    "keywords = []\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "for doc in tqdm(docs, desc=\"Extracting Keywords\"):\n",
    "    keywords.append(kw_model.extract_keywords(doc, stop_words='english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40660b56-ccfb-4b42-8e82-81675942ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('aorta', 0.6197)\n"
     ]
    }
   ],
   "source": [
    "print(keywords[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06b343ad-f056-41c3-abe6-5753effd05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for d in range(len(docs)):\n",
    "    # print(d, len(keywords[d]))\n",
    "    if(len(keywords[d]) > 0):\n",
    "        kw=keywords[d]\n",
    "        data.append([titles[d], docs[d], kw[0][0], kw[0][1], kw[1][0],kw[1][1],kw[2][0],kw[2][1], kw[3][0],kw[3][1], kw[4][0],kw[4][1]])\n",
    "\n",
    "#print(data[0][1])\n",
    "#print(docs[21])\n",
    "df=pd.DataFrame(data=data, columns=[\"Title\",\"Text\", \"Keyword1\",\"Score1\", \"Keyword2\", \"Score2\", \"Keyword3\", \"Score3\", \"Keyword4\",\"Score4\",\"Keyword5\", \"Score5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb1cfe62-7800-4569-83bd-7284e877baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv('keyword.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4368c6-3344-4dc2-9f6c-9e39f06d73d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
