{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1815641c-4b15-4d2e-8cb1-05dabbe2d11f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text has been successfully extracted to Reproductive_System.txt\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, txt_path):\n",
    "    # Open the PDF file\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    \n",
    "    # Iterate over each page in the PDF\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        # Extract text from the page\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    \n",
    "    # Write the text to a .txt file\n",
    "    with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "        txt_file.write(text)\n",
    "        \n",
    "    print(f\"Text has been successfully extracted to {txt_path}\")\n",
    "\n",
    "pdf_path = 'Reproductive_System.pdf' \n",
    "txt_path = 'Reproductive_System.txt' \n",
    "\n",
    "extract_text_from_pdf(pdf_path, txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5626288f-6214-4fe4-937f-f4bddfa6be5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reproductive: 27\n",
      "female: 25\n",
      "https: 24\n",
      "system: 23\n",
      "male: 19\n",
      "sperm: 18\n",
      "uterus: 15\n",
      "fertilization: 14\n",
      "penis: 13\n",
      "http: 13\n",
      "sexual: 12\n",
      "reproduction: 12\n",
      "mammals: 12\n",
      "within: 11\n",
      "eggs: 11\n",
      "ISBN: 11\n",
      "Reproductive: 10\n",
      "organs: 10\n",
      "species: 10\n",
      "females: 10\n",
      "\n",
      "Top 20 bigrams:\n",
      "('reproductive', 'system')\n",
      "('Wayback', 'Machine')\n",
      "('parental', 'care')\n",
      "('transfer', 'spermatophores')\n",
      "('internal', 'fertilization')\n",
      "('http', 'Archived')\n",
      "('fallopian', 'tubes')\n",
      "('Retrieved', 'November')\n",
      "('sexually', 'dimorphic')\n",
      "('ISBN', 'Retrieved')\n",
      "('Archived', 'https')\n",
      "('Reproductive', 'System')\n",
      "('contribute', 'towards')\n",
      "('flowering', 'plants')\n",
      "('exhibit', 'external')\n",
      "('great', 'diversity')\n",
      "('mother', 'pouch')\n",
      "('newborn', 'joey')\n",
      "('penises', 'ungulates')\n",
      "('secondary', 'sex')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "txt_path = 'Reproductive_System.txt'\n",
    "\n",
    "# with open(txt_path, 'r') as file:\n",
    "    # text = file.read()\n",
    "    \n",
    "# need encode to read specific char\n",
    "with open(txt_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [word for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
    "\n",
    "#freq_dist = FreqDist.tokenize(tokens) #notworking \n",
    "freq_dist = FreqDist(tokens)\n",
    "\n",
    "for word, frequency in freq_dist.most_common(20):\n",
    "    print(f\"{word}: {frequency}\")\n",
    "\n",
    "bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "bigrams = bigram_finder.nbest(BigramAssocMeasures.likelihood_ratio, 20)\n",
    "\n",
    "print(\"\\nTop 20 bigrams:\")\n",
    "for bigram in bigrams:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad905baa-2d23-4237-b464-957a18461e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# txt_path = 'Oxygen.txt'\n",
    "# with open(txt_path, 'r', encoding='utf-8') as file:\n",
    "#     text = file.read()\n",
    "    \n",
    "# summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# def summarize_text(text, max_length=150):\n",
    "#     summary = summarizer(text, max_length=max_length, min_length=30, do_sample=False)\n",
    "#     return summary[0]['summary_text']\n",
    "\n",
    "# summary = summarize_text(text)\n",
    "# print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe083e-04cb-4bdb-b06c-5477b42add49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
