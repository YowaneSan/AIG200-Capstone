{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f83c3ce-1a49-48b3-8994-65150b869d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User prompt: 'heart'\n",
      "Top 3 associated page names:\n",
      "1. Heart (Relevance Score: 0.412)\n",
      "2. Cardiac_muscle (Relevance Score: 0.227)\n",
      "3. Circulatory_system (Relevance Score: 0.197)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load your keyword data\n",
    "keywords_df = pd.read_csv('keyword.csv')\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the \"text\" column to TF-IDF matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(keywords_df['Text'].fillna(''))\n",
    "\n",
    "\n",
    "def match_top_pages(user_prompt, keywords_df, tfidf_matrix, top_n=5):\n",
    "    processed_prompt = user_prompt.lower()  #lowercase\n",
    "    keywords = processed_prompt.split()  # split by whitespace\n",
    "    \n",
    "    relevance_scores = {}\n",
    "    \n",
    "    # loop match keywords\n",
    "    for keyword in keywords:\n",
    "        # Filter rows where keyword appears in any keyword column\n",
    "        matches = keywords_df[keywords_df.apply(lambda x: keyword in x.values, axis=1)]\n",
    "        \n",
    "        # Calculate relevance scores \n",
    "        for index, row in matches.iterrows():\n",
    "            relevance_score = row[['Score1', 'Score2', 'Score3', 'Score4', 'Score5']].sum()\n",
    "            page_name = row['Title']  # Get the page name\n",
    "            if page_name in relevance_scores:\n",
    "                relevance_scores[page_name] += relevance_score\n",
    "            else:\n",
    "                relevance_scores[page_name] = relevance_score\n",
    "    \n",
    "    # If no matches found in keywords, search in the \"text\" column using TF-IDF\n",
    "    if not relevance_scores:\n",
    "        # convert to matrix\n",
    "        user_tfidf = tfidf_vectorizer.transform([user_prompt])\n",
    "        \n",
    "        #cosine similarity between  user prompt and TF-IDF matrix\n",
    "        cosine_similarities = cosine_similarity(user_tfidf, tfidf_matrix).flatten()\n",
    "        \n",
    "        # Get top N indices of the most similar documents\n",
    "        top_indices = cosine_similarities.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        for index in top_indices:\n",
    "            page_name = keywords_df.iloc[index]['Title']\n",
    "            relevance_score = cosine_similarities[index]\n",
    "            relevance_scores[page_name] = relevance_score\n",
    "    \n",
    "    sorted_pages = sorted(relevance_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_pages = sorted_pages[:top_n]\n",
    "    \n",
    "    return top_pages\n",
    "\n",
    "user_prompt = \"heart\"\n",
    "top_n = 3  # Number of top pages to retrieve\n",
    "top_pages = match_top_pages(user_prompt, keywords_df, tfidf_matrix, top_n=top_n)\n",
    "\n",
    "print(f\"User prompt: '{user_prompt}'\")\n",
    "if top_pages:\n",
    "    print(f\"Top {top_n} associated page names:\")\n",
    "    for i, (page_name, relevance_score) in enumerate(top_pages, 1):\n",
    "        print(f\"{i}. {page_name} (Relevance Score: {round(relevance_score,3)})\")\n",
    "else:\n",
    "    print(\"No relevant pages found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e2ae0c9-5487-4592-a07c-427930bb70d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page2: 0.8012697309925455\n",
      "Page3: 0.7605744071250108\n",
      "Page1: 0.5097436192149191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keror\\AppData\\Local\\Temp\\ipykernel_16264\\831572701.py:12: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  return prompt_vector.similarity(keyword_vector)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Process the user prompt\n",
    "user_prompt = \"I want to learn about blood vessels\"\n",
    "processed_prompt = nlp(user_prompt.lower())\n",
    "# Sample keywords DataFrame\n",
    "def calculate_similarity(prompt_vector, keyword):\n",
    "    keyword_vector = nlp(keyword.lower())\n",
    "    return prompt_vector.similarity(keyword_vector)\n",
    "\n",
    "data = {\n",
    "    'Title': ['Page1', 'Page2', 'Page3'],\n",
    "    'Keyword_1': ['blood', 'vessels', 'heart'],\n",
    "    'Score1': [0.8, 0.9, 0.7],\n",
    "    'Keyword_2': ['circulation', 'veins', 'artery'],\n",
    "    'Score2': [0.6, 0.8, 0.9],\n",
    "    'Keyword_3': ['artery', 'capillaries', 'cardiovascular'],\n",
    "    'Score3': [0.7, 0.6, 0.8],\n",
    "    'Keyword_4': ['vein', 'blood flow', 'pulse'],\n",
    "    'Score4': [0.5, 0.7, 0.6],\n",
    "    'Keyword_5': ['capillary', 'blood vessel', 'blood pressure'],\n",
    "    'Score5': [0.4, 0.5, 0.7]\n",
    "}\n",
    "keywords_df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize a dictionary to store relevance scores\n",
    "relevance_scores = {}\n",
    "\n",
    "# Iterate over rows in the DataFrame\n",
    "for index, row in keywords_df.iterrows():\n",
    "    page_name = row['Title']\n",
    "    total_relevance_score = 0\n",
    "    \n",
    "    # Check similarity with each keyword\n",
    "    for i in range(1, 6):\n",
    "        keyword = row[f'Keyword_{i}']\n",
    "        score = row[f'Score{i}']\n",
    "        similarity = calculate_similarity(processed_prompt, keyword)\n",
    "        total_relevance_score += similarity * score\n",
    "    \n",
    "    # Store the relevance score\n",
    "    if page_name in relevance_scores:\n",
    "        relevance_scores[page_name] += total_relevance_score\n",
    "    else:\n",
    "        relevance_scores[page_name] = total_relevance_score\n",
    "        \n",
    "# Sort pages by relevance scores\n",
    "sorted_relevance = sorted(relevance_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print sorted relevance scores\n",
    "for page, score in sorted_relevance:\n",
    "    print(f\"{page}: {score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91313888-eb12-453f-9df6-424dfa236a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
